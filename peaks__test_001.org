


* LINKS

- https://colab.research.google.com/#create=true&language=r
- https://towardsdatascience.com/how-to-use-r-in-google-colab-b6e02d736497

* PROD: FIRST

#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

"""
get_ipython().magic("run peaks__test_001.tg.ipy")

"""

get_ipython().magic("load_ext autoreload")
get_ipython().magic("autoreload 2"       )

import os
import sys
import numpy as np
import pandas as pd
import json

import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

from collections import OrderedDict

import deepsensemaking as dsm
from   deepsensemaking.dicts import str_dict,print_dict
from   deepsensemaking.bids  import get_bids_prop
from   deepsensemaking.eeg   import convert_ZZ
from   deepsensemaking.eeg   import chan_bund_INEFFICIENT_mean

from IPython.display import display, HTML

_DIR = dsm.set_cwd()

pd.set_option("display.notebook_repr_html", dsm.base.outside_emacs() )


# %matplotlib notebook


from contextlib import ExitStack
mgrs = [
    pd.option_context("display.max_columns"  ,   45),
    pd.option_context("display.max_colwidth" ,   80),
    pd.option_context("display.width"        ,  800),
    pd.option_context("display.max_rows"     ,  200),
    pd.option_context("display.min_rows"     ,  200),
]

with ExitStack() as stack:
    [stack.enter_context(mgr) for mgr in mgrs]
    print( pd.get_option("display.max_rows") )


ifSetup="peaks/data/setup.json"
with open(ifSetup) as fhSetup: setup = OrderedDict(json.load(fhSetup))
print_dict(setup,"setup",1,)


#+END_SRC



#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

ifZ0 = "peaks/data/corr_bv_database_EEG_LONG.csv"
dfZ0 = pd.read_csv(ifZ0)

dfZ1 = convert_ZZ(dfZ0,ifSetup="peaks/data/setup.json",verbose=3,)
dfZ1.shape

ofZ1 = "peaks/data/dfZ1_peaks_crude_CONVERTED.csv"
dfZ1.to_csv(ofZ1,index = False,)


#+END_SRC



#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

ifC3 = "peaks/data/df4_peaks4_crude.csv"
ifZ3 = "peaks/data/dfZ1_peaks_crude_CONVERTED.csv"

dfC3 = pd.read_csv(ifC3)
dfZ3 = pd.read_csv(ifZ3)

print(dfC3.shape)
print(dfZ3.shape)

dfZ4 = chan_bund_INEFFICIENT_mean(dfZ3)
ofZ4 = "peaks/data/dfZ4_peaks_crude_XTRA_MEANS.csv"
dfZ4.to_csv(ofZ4,index=False,)

dfC4 = chan_bund_INEFFICIENT_mean(dfC3)
ofC4 = "peaks/data/dfC4_peaks_crude_XTRA_MEANS.csv"
dfC4.to_csv(ofC4,index=False,)


#+END_SRC


* PROD: SECOND


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

get_ipython().magic("load_ext autoreload")
get_ipython().magic("autoreload 2")

import os
import sys
import numpy as np
import pandas as pd
import json

import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

from collections import OrderedDict

import deepsensemaking as dsm
from   deepsensemaking.dicts import str_dict,print_dict
from   deepsensemaking.bids  import get_bids_prop
from   deepsensemaking.eeg   import convert_ZZ
from   deepsensemaking.eeg   import chan_bund_INEFFICIENT_mean

from IPython.display import display, HTML

_DIR = dsm.set_cwd()

pd.set_option("display.notebook_repr_html", dsm.base.outside_emacs() )

# %matplotlib notebook

from contextlib import ExitStack
mgrs = [
    pd.option_context("display.max_columns"  ,   45),
    pd.option_context("display.max_colwidth" ,   80),
    pd.option_context("display.width"        ,  800),
    pd.option_context("display.max_rows"     ,  200),
    pd.option_context("display.min_rows"     ,  200),
]

with ExitStack() as stack:
    [stack.enter_context(mgr) for mgr in mgrs]
    print( pd.get_option("display.max_rows") )

def dispDF(df_TEMP,n=6):
    with ExitStack() as stack:
        [stack.enter_context(mgr) for mgr in mgrs]
        display(df_TEMP.shape)
        display(df_TEMP.sample(n=n).sort_index())


ifSetup="peaks/data/setup.json"
with open(ifSetup) as fhSetup: setup = OrderedDict(json.load(fhSetup))
print_dict(setup,"setup",1,)

ifZ0 = "peaks/data/corr_bv_database_EEG_LONG.csv"
dfZ0 = pd.read_csv(ifZ0)

dfZ1 = convert_ZZ(dfZ0,ifSetup="peaks/data/setup.json",verbose=3,)
dfZ1.shape

#+END_SRC


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes


ifC3 = "peaks/data/df4_peaks4_crude.csv"
ifZ3 = "peaks/data/dfZ1_peaks_crude_CONVERTED.csv"
ifC4 = "peaks/data/dfC4_peaks_crude_XTRA_MEANS.csv"
ifZ4 = "peaks/data/dfZ4_peaks_crude_XTRA_MEANS.csv"

dfC3 = pd.read_csv(ifC3)
dfZ3 = pd.read_csv(ifZ3)
dfC4 = pd.read_csv(ifC4)
dfZ4 = pd.read_csv(ifZ4)

# dfZ3 and dfZ4 should contain only columns that are present in dfC3 and dfC4
dfZ3 = dfZ3[dfC3.columns]
dfZ4 = dfZ4[dfC4.columns]

list(dfC3.columns)



#+END_SRC


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

cols0 = dfZ3.columns
cols1 = [col0 for col0 in cols0 if col0 not in ["valX","latX","RUN"]]
dfZ0 = dfZ3.groupby(by=cols1,as_index=False).agg("mean")
dfZ0["RUN"]  = 0
dfZ0 = dfZ0[cols0]
dfZ0




#+END_SRC


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

dfS0 = dfZ0.copy()
dfS0 = chan_bund_INEFFICIENT_mean(dfS0)


#+END_SRC


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

temp_rename = {
    "CHAN_BUND":"bund0",
    "SUB":"subj0",
    "RUN":"runn0",
}
temp_drop = [
    "SES",
    "TASK",
]

dfC3.rename(columns=temp_rename,inplace=True,)
dfZ3.rename(columns=temp_rename,inplace=True,)
dfC4.rename(columns=temp_rename,inplace=True,)
dfZ4.rename(columns=temp_rename,inplace=True,)
dfZ0.rename(columns=temp_rename,inplace=True,)
dfS0.rename(columns=temp_rename,inplace=True,)

dfC3.drop(columns=temp_drop,inplace=True,)
dfZ3.drop(columns=temp_drop,inplace=True,)
dfC4.drop(columns=temp_drop,inplace=True,)
dfZ4.drop(columns=temp_drop,inplace=True,)
dfZ0.drop(columns=temp_drop,inplace=True,)
dfS0.drop(columns=temp_drop,inplace=True,)

dfC3["set0"] = "C3chan"
dfZ3["set0"] = "Z3chan"
dfC4["set0"] = "C4bund"
dfZ4["set0"] = "Z4bund"
dfZ0["set0"] = "Z0chan"
dfS0["set0"] = "Z0bund"


dfC3.loc[ dfC3["bund0"].isnull(), "set0" ] = "C3bund"

assert list(dfC3.columns)==list(dfC4.columns)
assert list(dfC3.columns)==list(dfZ3.columns)
assert list(dfC3.columns)==list(dfZ4.columns)
assert list(dfC3.columns)==list(dfZ0.columns)
assert list(dfC3.columns)==list(dfS0.columns)

display(list(dfC3.columns))




#+END_SRC

#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

dispDF(dfC3,12,)
dispDF(dfZ3,12,)
dispDF(dfC4,12,)
dispDF(dfZ4,12,)
dispDF(dfZ0,12,)
dispDF(dfS0,12,)

list(dfZ3.columns)


display(dfZ3.set0.unique())
display(dfC3.set0.unique())


#+END_SRC

#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

dfC5 = dfC3.append(dfC4, ignore_index=True)
dfZ5 = dfZ3.append([dfZ4,dfZ0,dfS0], ignore_index=True)


#+END_SRC


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

# dfC5 should keep only `chan0` levels that are present in the corresponding dfZ5 column
# effectively this drops from dfC5 channels that are not of interest
dfC5 = dfC5[ np.isin( dfC5["chan0"], dfZ5["chan0"].unique() ) ]
display(dfC5.shape)
display(dfZ5.shape)
assert sorted(list(dfC5["chan0"].unique())) == sorted(list(dfZ5["chan0"].unique()))


# dfC5 should keep only `cond0` levels that are present in corresponding dfZ5 column
# effectively this drops from dfC5 dummy condition containing all ERPs and
# any conditions based on word length ETC
dfC5 = dfC5[ np.isin( dfC5["cond0"], dfZ5["cond0"].unique() ) ]
display(dfC5.shape)
display(dfZ5.shape)
assert sorted(list(dfC5["cond0"].unique())) == sorted(list(dfZ5["cond0"].unique()))


# BACKUP subjects codes data
# This is used below to explain a missing/misslabeled subject
# This subject (27mwxf/27zgxf) will be removed from this comparison
subjC5 = dfC5["subj0"].unique()
subjZ5 = dfZ5["subj0"].unique()

# Seems that we have an extra subject in the dfZZ database
# Actually the label seems to be mixed up for subject 27mwxf/27zgxf
# I have a vauge memory that we have discussed this isue already
set(subjZ5).difference(set(subjC5))



# dfC5 should keep only `SUB` levels that are present in corresponding dfZ5 column
# effectively this drops from dfC5 subjects not present in dfZ5

# HOT FIX # TODO verify again that this is all hunky-dory
dfZ5["subj0"] = dfZ5["subj0"].str.replace("27mwxf","27zgxf")
dfC5 = dfC5[ np.isin( dfC5["subj0"], dfZ5["subj0"].unique() ) ]
display(dfC5.shape)
display(dfZ5.shape)



assert sorted(dfC5["subj0"].unique())==sorted(dfZ5["subj0"].unique())
assert sorted(dfC5["chan0"].unique())==sorted(dfZ5["chan0"].unique())
assert sorted(dfC5["cond0"].unique())==sorted(dfZ5["cond0"].unique())
assert sorted(dfC5["tmin0"].unique())==sorted(dfZ5["tmin0"].unique())






dispDF(dfC5,12)

dispDF(dfZ5,12)





dispDF(dfC5,44)

dispDF(dfZ5,44)









#+END_SRC




#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

dfA0 = dfC5.append(dfZ5, ignore_index=True)
dfA0.shape
dispDF(dfA0,25)


#+END_SRC


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes


# Expected number of basic cases
temp_expect = dict(
    cond0 =  4,
    chan0 = 36,
    tmin0 =  6,
    subj0 = 32,
)
temp_expect = np.prod(list(temp_expect.values()))

# C3chan has only one run (0) but two levels for mode0 (pos, neg)
temp_C3chan_pos1 = len(dfA0.query(""" set0=="C3chan" & mode0=="pos" """))
assert temp_expect == temp_C3chan_pos1

# Z3chan has only one level for mode0 (pos) but four levels for run (1, 2, 3, 4)
temp_Z3chan_run1 = len(dfA0.query(""" set0=="Z3chan" & runn0==1 """ ))
assert temp_expect == temp_Z3chan_run1

# Analogous to the above
temp_C3bund_pos1 = len(dfA0.query(""" set0=="C3bund" & mode0=="pos" """))
temp_C4bund_pos1 = len(dfA0.query(""" set0=="C4bund" & mode0=="pos" """))
temp_Z4bund_run1 = len(dfA0.query(""" set0=="Z4bund" & runn0==1     """))
temp_Z0chan_run0 = len(dfA0.query(""" set0=="Z0chan" & runn0==0     """))
temp_Z0bund_run0 = len(dfA0.query(""" set0=="Z0bund" & runn0==0     """))

assert temp_expect == temp_C3bund_pos1 * 6
assert temp_expect == temp_C4bund_pos1 * 6
assert temp_expect == temp_Z4bund_run1 * 6
assert temp_expect == temp_Z0chan_run0
assert temp_expect == temp_Z0bund_run0 * 6

display(temp_expect)
display(temp_C3chan_pos1)
display(temp_Z3chan_run1)
display(temp_C3bund_pos1)
display(temp_C4bund_pos1)
display(temp_Z4bund_run1)
display(temp_Z0chan_run0)
display(temp_Z0bund_run0)

# Each of six bundles contains six channels
display(temp_Z4bund_run1 * 6)

del temp_expect
del temp_C3chan_pos1
del temp_Z3chan_run1
del temp_C3bund_pos1
del temp_C4bund_pos1
del temp_Z4bund_run1
del temp_Z0chan_run0
del temp_Z0bund_run0


#+END_SRC



#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

dfA0.to_csv("peaks/data/dfA0.csv",index=False,)


#+END_SRC

#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

# dfA0.drop(columns=["evoked0","quest0","tmax0","chanX","latX","SES","TASK"],inplace=True,errors="ignore",)

dfA0 = dfA0[["cond0","chan0","bund0","tmin0","mode0","subj0","runn0","set0","valX",]]

dfA0 = dfA0[["set0","mode0","cond0","chan0","bund0","tmin0","runn0","subj0","valX",]]

dispDF(dfA0,24)
display(list(dfA0.columns))



#+END_SRC


* PROD: Third

#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

get_ipython().magic("load_ext autoreload")
get_ipython().magic("autoreload 2")

import os
import sys
import numpy as np
import pandas as pd
import json

import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

from collections import OrderedDict

import deepsensemaking as dsm
from   deepsensemaking.dicts import str_dict,print_dict
from   deepsensemaking.bids  import get_bids_prop
from   deepsensemaking.eeg   import convert_ZZ
from   deepsensemaking.eeg   import convert_ZZ_translators
from   deepsensemaking.eeg   import chan_bund_INEFFICIENT_mean

from IPython.display import display, HTML, Image

_DIR = dsm.set_cwd()

pd.set_option("display.notebook_repr_html", dsm.base.outside_emacs() )

# %matplotlib notebook


import scipy as sp
import matplotlib as mpt
import pingouin as pg
import outdated as od
import statsmodels as sm
import mpmath as mmp
import sklearn as skl
import pandas.util.testing as tm
from scipy import stats as sp
from pingouin import  pairwise_ttests, read_dataset

import seaborn as sns


# The following is only for my GNU Emacs configuration to suppress HTML output
if "DIR_PROJ_MAIN" in locals(): pd.options.display.notebook_repr_html = False


from contextlib import ExitStack
mgrs = [
    pd.option_context("display.max_columns"  ,   45),
    pd.option_context("display.max_colwidth" ,   80),
    pd.option_context("display.width"        ,  800),
    pd.option_context("display.max_rows"     ,  200),
    pd.option_context("display.min_rows"     ,  200),
]

with ExitStack() as stack:
    [stack.enter_context(mgr) for mgr in mgrs]
    print( pd.get_option("display.max_rows") )

def dispDF(df_TEMP,n=6):
    with ExitStack() as stack:
        [stack.enter_context(mgr) for mgr in mgrs]
        display(df_TEMP.shape)
        display(df_TEMP.sample(n=n).sort_index())



ifA0 = "peaks/data/dfA0.csv"
dfA0 = pd.read_csv(ifA0)
dfA1 = dfA0[["set0","mode0","cond0","chan0","bund0","tmin0","runn0","subj0","valX",]]
display(list(dfA1.columns))





#+END_SRC

* CTRL: Extras


#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

cols0 = [col0 for col0 in dfZ4.columns if col0 not in ["latX","valX",]]
dups0 = dfZ4.duplicated(subset=cols0,keep="first")

cols0 = [col0 for col0 in dfZ3.columns if col0 not in ["latx","valX","evoked"]]
dfZ3.groupby(by=cols0).mean()

for df0 in []


dfZ3
dfZ4
dfC3
dfC4

cols0 = [col0 for col0 in df_TEMP.columns if col0 not in ["latX","valX",]]
dups0 = df_TEMP.duplicated(subset=cols0,keep="first")
sum(dups0)



#+END_SRC



#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes
cols0 = list(dfC5.columns)
cols0 = [col0 for col0 in cols0 if col0 not in ["evoked0","mode0","latX","valX","RUN","CHAN_BUND"] ]
for col0 in cols0:
  assert sorted(dfC5[col0].unique())==sorted(dfZ5[col0].unique()), "PROBLEM: {}".format(col0)



display(sorted(dfZ5["CHAN_BUND"].fillna("").unique()))
assert sorted(dfC5["CHAN_BUND"].fillna("").unique())==sorted(dfZ5["CHAN_BUND"].fillna("").unique()), "PROBLEM: {}".format(col0)




#+END_SRC



#+BEGIN_SRC ipython :session *iPython* :eval yes :results raw drawer :exports both :shebang "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n" :var EMACS_BUFFER_DIR=(file-name-directory buffer-file-name) :tangle yes

# Expected number of basic cases
temp_expect = dict(
    cond0 =  4,
    chan0 = 36,
    tmin0 =  6,
    subj0 = 32,
)
temp_expect = np.prod(list(temp_expect.values()))

# C3chan has only one run (0) but two levels for mode0 (pos, neg)
temp_C3chan_pos1 = sum((dfA0["set0"]=="C3chan") & (dfA0["mode0"]=="pos"))
assert temp_expect == temp_C3chan_pos1

# Z3chan has only one level for mode0 (pos) but four levels for run (1, 2, 3, 4)
temp_Z3chan_run1 = sum((dfA0["set0"]=="Z3chan") & (dfA0["RUN"]==1))
assert temp_expect == temp_Z3chan_run1

# Analogous to the above
temp_C3bund_pos1 = sum((dfA0["set0"]=="C3bund") & (dfA0["mode0"]=="pos"))
temp_C4bund_pos1 = sum((dfA0["set0"]=="C4bund") & (dfA0["mode0"]=="pos"))
temp_Z4bund_run1 = sum((dfA0["set0"]=="Z4bund") & (dfA0["RUN"]==1))

assert temp_expect == temp_C3bund_pos1 * 6
assert temp_expect == temp_C4bund_pos1 * 6
assert temp_expect == temp_Z4bund_run1 * 6

display(temp_expect)
display(temp_C3chan_pos1)
display(temp_Z3chan_run1)
display(temp_C3bund_pos1)
display(temp_C4bund_pos1)
display(temp_Z4bund_run1)
# Each of six bundles contains six channels
display(temp_Z4bund_run1 * 6)

del temp_expect,temp_C3chan_pos1,temp_Z3chan_run1,temp_C3bund_pos1,temp_C4bund_pos1,temp_Z4bund_run1



#+END_SRC
